\documentclass[a4paper,spanish]{article}

\usepackage{url}
\usepackage{tabu}
\usepackage{float}
\usepackage{cite}
\usepackage[spanish]{cleveref}
\usepackage[colorlinks]{hyperref}
\usepackage{fancyvrb}

\bibliographystyle{unsrt}

\input{preambulo}



\begin{document}

\input{caratula}
\tableofcontents
\pagebreak


\section{Resumen}
En el siguiente trabajo práctico resolveremos un problema NP-Completo llamado
Sudoku. Mostraremos una estrategia de resolución exacta y una metaheurística
para resolver el problema. Finalmente mostraremos los resultados de aplicar la
metaheurística.


\section{Introducción}
\label{sec:intro}

El juego \emph{Sudoku} es un rompecabezas lógico que trata la ubicación de
números en una grilla de $N^2 x N^2$. Este tiene celdas con valores ya fijados,
llamados \textit{pistas}, y el objetivo es completar las celdas
faltantes con valores de $1..N^2$. La grilla se subdivide en $N$ cuadrantes de
$N x N$  y se debe completar cumpliendo con las siguientes reglas:

\begin{enumerate}
    \label{enum:principios}

    \item Cada fila debe tener los valores de 1 a N una única vez
    \item Cada columna debe tener los valores de 1 a N una única vez
    \item Cada subcuadrante de $NxN$ debe tener los valores de 1 a N una única vez
\end{enumerate}

Un ejemplo de este tipo de problemas tan conocido se observa en la tabla
\ref{img:sudoku}


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{./img/sudoku.png}
	\caption{Sudoku ejemplo}
	\label{img:sudoku}
\end{figure}

Durante los últimos tiempos, han surgido diversos métodos para resolver
de manera heurística el problema dada su complejidad.

Los métodos de resolución exacta para este problema con \emph{Fuerza bruta}
consisten en asignar posibles valores iterativamente a las celdas e ir
verificando si el sudoku cumple las reglas a medida que se siguen completando
los blancos.

Este algoritmo de resolución es costoso y a menudo se utiliza con backtracking.


En la actualidad se han encontrado avances en la resolución de Sudoku utilizando
algorítmos genéticos \cite{mantere}, Búsqueda harmónica
\cite{harmony} y Ant Colony \cite{ant_colony} entre otros.

Para este trabajo práctico, implementamos una metaheurística de Ant Colony, y una
de búsqueda local, que transforma el Sudoku en un problema de coloreo de grafos y
luego utiliza DSatur\cite{dsatur} como heurística.


\section{Búsqueda Local - DSatur}

Supongamos que tenemos un problema al que queremos encontrarle una solución
óptima, este problema toma diversos parámetros y por cada instancia
devuelve una solución que puede ser correcta en términos de las restricciones
del problema, puede ser óptima en términos de ser la mejor solución, o puede ser
ninguna de las anteriores. En este último caso, evaluaremos si siguiendo por esa
solución parcial del problema alcanzaremos una solución que sea a la vez
correcta y óptima.

Una solución óptima puede no ser siempre alcanzable y en ese caso se busca la
mejor solución. Se dice que una solución $S_1$ es mejor que solución $S_2$ si
dada una función objetivo  que toma instancias de solución nos permite
compararlas para determinar si una es mejor que la otra.

\begin{equation}
    f(S_1) < f(S_2) 
\end{equation}


El método de Búsqueda local entonces, itera sobre el espacio de soluciones
buscando en cada paso obtener una mejor solución parcial hasta alcanzar un
mínimo. Luego de la estabilización, este se detiene.

¿Qué sucede si el método no alcanzó el mínimo absoluto? Este se estanca
en una solución que no se encuentra cercana al valor óptimo y terminará
arrojando un mínimo local.

\clearpage

\section{Desarrollo}


En la sección anterior presentamos la noción de una metaheurística de búsqueda local.
Ahora necesitamos definir como transformamos el problema de resolver un Sudoku
a un problema de coloreo de grafos.
Ademas, definiremos la función objetivo y la función de vecindad.
Para todos los casos, utilizamos los Sudoku de $ 9x9 $.

REVISAR 

\subsection{Transformación}
\label{sec:transformacion}

La transformación es bastante trivial, cada celda del Sudoku es representada por
un nodo en el Grafo, y la fila, columna y el subcuadrante asociado son los nodos
adyacentes como muestra \ref{img:adyacentes}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{./img/adyacentes.png}
    \caption{Nodos adyacentes}
    \label{img:adyacentes}
\end{figure}

Esta es la estructura básica del grafo, luego tenemos que transformar las pistas
(números que vienen fijos) en colores de manera unívoca. \ref{img:color_map}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{./img/numero_color.png}
    \caption{Asociación de Pistas a Colores}
    \label{img:color_map}
\end{figure}

\clearpage

Con esto, ya contamos con el grafo inicial \ref{img:grafo_inicial} y podemos
comenzar a colorearlo con el algoritmo que elegimos.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{./img/grafo_inicial.png}
    \caption{Grafo Inicial}
    \label{img:grafo_inicial}
\end{figure}

A su vez, de este grafo podemos extraer varias propiedades:

\begin{itemize}
	\item 81 nodos
	\item Clique Máxima: 9
	\item Todo nodo pertenece a una clique máxima
	\item $ grado(n_i) = 20 $
	\item $ \chi(G) = 9 $
\end{itemize}


\subsection{Algoritmo}

Los algoritmos de coloreo secuencial, también conocidos como coloreo goloso van seleccionando un nodo
de acuerdo a algún criterio específico, formando así un \emph{orden} de coloración.
Luego, en cada nodo lo van coloreando con un color que no tienen sus vecinos.
 
El orden en que se seleccionan los nodos afectan a la coloración, así que un buen orden de
vértices puede traducirse en una buena coloración. No hay ninguna forma de obtener la solución óptima,
sino que, se aplica el algoritmo de coloración secuencial varias veces hasta obtener la coloración válida.
 
​Los algoritmos de coloreo secuencial proponen las siguientes variantes:
 
\begin{itemize}
	\item \emph{Largest Degree Ordering (LDO)} - Los vértices son ordenados en orden descendente de acuerdo a su grado. La idea aquí  es que los vértices de mayor grado serán más difíciles de colorear al último, y por eso se colorean primero.
	\item \emph{Saturation Degree Ordering (SDO)} - A diferencia de \emph{LDO} donde el orden de los vértices se determina de antemano, aquí los vértices son seleccionados durante el proceso de coloración. En saturación, el vértice con el grado de saturación más alta se selecciona para ser el próximo a colorear. El grado de saturación de un vértice es el número de colores diferentes usados por sus vecinos. La idea es seleccionar el vértice que está más restringido.
	\item \emph{Incidence Degree Ordering (IDO)} - Es una modificación de \emph{SDO}, el grado de incidencia de un nodo esta definido como el número de vértices adyacentes coloreados.
\end{itemize}
 

\subsection{Solución inicial - \emph{SDO}}

Nuestra solución inicial está definida de manera de elegir los nodos con
grado de saturación más alto primero, y asignarles el primer color disponible.

\begin{Verbatim}[samepage=true]
while (ColoredNodes < 81) {
  for all the nodes {
    node = NodeWithMaxSaturatedDegree

    if not colored(node) {
      AssignFirstAvailableColor(node)
  	  ColoredNodes = ColoredNodes + 1
    }
  }
}
\end{Verbatim}

\subsection{Nodos Conflictivos}

Dado que es un algoritmo goloso, es altamente probable que no de una solución optima.
En los casos que no se pueda asignar un color, o un número del 1-9, el algoritmo
utiliza números mas grandes, y continua buscando una solución.

Decimos que un nodo es conflictivo si cumple la siguiente condición:

\begin{equation}
    hasColor \wedge isNotAClue \wedge ( color > 9 \vee adjacentUsesSameColor)
\end{equation}

%%%%Cuando arrojamos una solución con nodos conflictivos, hacemos una búsqueda local

\subsection{Función objetivo}

Definiremos la función objetivo como la suma de la cantidad de nodos conflictivos. 
Esta función vale cero cuando la solución del sudoku es correcta.

Definimos la función objetivo de la siguiente manera: 

\begin{Verbatim}[samepage=true]
for node in SudokuNodes {
  if Conflictive(node)
    count++
}

return count
\end{Verbatim}


\subsection{Función de vecindad}

Definimos nuestra función de vecindad que toma un Sudoku como fue
definido en \ref{sec:transformacion}.


Intercambiaremos un valor (seleccionado al azar) dentro de la matriz por otro
dentro del mismo cuadrante, también seleccionado al azar. Tendremos cuidado en
no intercambiar los valores que ya vinieron fijos en el sudoku de entrada.

\begin{Verbatim}[samepage=true]
function(mat){
  // obtenemos dos indices al azar dentro del rango de la matriz
  i_j = sample(1:N2, 2) 
  // Otenemos dos indices al azar dentro del mismo subcuadrante
  l_k = get_next_index(i_j)
  // si son iguales o es una celda fija generamos otro par de indices
  if(all(i_j == l_k) | is_fixed(i_j)){
    return(gen_neighbourgh(mat))
  }
  // Si obtuvimos indices validos intercambiamos los valores y retornamos la
  matriz
  tmp = mat[i_j[1], i_j[2]]
  mat[i_j[1], i_j[2]] = mat[l_k[1], l_k[2]]
  mat[l_k[1], l_k[2]] = tmp
  return(mat)
}

    
\end{Verbatim}


\clearpage

\section{Casos de prueba - HACER !!!}

DEJO ESTE TEXTO COMO EJEMPLO

Para evaluar el comportamiento de ambos algorítmos utilizamos casos de prueba
generados con la aplicación \emph{qqwing}\footnote{\url{http://qqwing.com/}}. Este nos permite generar tableros
sudoku de distinta dificultad.

Para esto generamos veinte tableros de cada tipo de dificultad para poder
evaluar el comportamiento de ámbos algorítmos y la asignación reportada por cada
uno.

Los tableros generados fueron del tipo facil, medio y difícil. Cada uno está
determinado por la dificultad de resolución lógico deductiva. Esto lo hicimos de
esta manera para poder mostrar la relación entre este tipo de dificultad y la
corrida de los algoritmos.

Para las figuras  \ref{img:histo_easy}, \ref{img:histo_med} y
\ref{img:histo_hard}, corrimos ambos algoritmos con un set de 20 instancias de
sudoku generadas al azar para determinar cual es la eficacia del altorítmo para
3000 iteraciones (este valor se determinó empiricamente en base a esperimentos
anteriores).
Podemos observar la cantidad de soluciones óptimas que ha obtenido cada
algorítmo. Observamos que Threshold Accepting supera a Búsqueda local por más de
un 50\%.

También se observa que la convergencia de las soluciones es buena, es decir que
todos los valores que se han obtenido están en un entorno cercano a la solución
óptima.


\begin{center}
    \begin{figure}
        \includegraphics[width=\textwidth]{./imgs/problemas_easy_histo.png}
        \caption{Histograma asignación Búsqueda local (LS) y Threshold
        Accepting (TA) para el conjunto de problemas fácil)}
        \label{img:histo_easy}
    \end{figure}
\end{center}
\begin{center}
    \begin{figure}
        \includegraphics[width=\textwidth]{./imgs/problemas_med_histo.png}
        \caption{Histograma asignación Búsqueda local (LS) y Threshold
        Accepting (TA) para el conjunto de problemas mediano}
        \label{img:histo_med}
    \end{figure}
\end{center}
\begin{center}
    \begin{figure}
        \includegraphics[width=\textwidth]{./imgs/problemas_hard_histo.png}
        \caption{Histograma asignación Búsqueda local (LS) y Threshold
        Accepting (TA) para el conjunto de problemas difícil}
        \label{img:histo_hard}
    \end{figure}
\end{center}

También observamos que en \ref{img:histo_med} la obtención del óptimo es mucho
mayor. Cosa que no se reproduce en \ref{img:histo_easy} ni en
\ref{img:histo_hard}. Esto nos muestra que no depende de la facilidad de
resolución del problema (en términos lógico deductivos) sino más bien en la
distribución de los vecinos.

Si observamos el comportamiento de los algoritmos con un tablero fijo y variando
la cantidad de iteraciones que precisa para alcanzar el óptimo obtenemos las
figuras \ref{img:prog_ls} y \ref{img:prog_ta}. Para esto se generaron 50
corridas de asignación variando la cantidad de iteraciones admitidas para el
algoritmo de 100 a 3000.

Las figuras presentan las medias y varianzas observacionales de los
experimentos.


\begin{center}
    \begin{figure}[H]
        \includegraphics[width=\textwidth]{./imgs/BLsol_progresion.png}
        \caption{Progresión de parámetro máxima cantidad de iteraciones para Búsqueda Local}
        \label{img:prog_ls}
    \end{figure}
\end{center}


\begin{center}
    \begin{figure}[H]
        \includegraphics[width=\textwidth]{./imgs/TAsol_progresion.png}
        \caption{Progresión de parámetro máxima cantidad de iteraciones para
        Threshold Accepting}
        \label{img:prog_ta}
    \end{figure}
\end{center}

Determinamos que los algoritmos se estabilizan luego de las 3000 iteraciones
aunque la varianza para la asignación es muy elevada. Esto nos indica que el
espacio de soluciones es muy grande y por lo tanto en algunos casos los mínimos locales
alcanzados son difíciles de sobrellevar.



\section{Discusión}

En este trabajo experimentamos con la resolución del problema de Sudoku con dos
heurísticas distintas: de búsqueda local y Ant Colony.

Encontramos que Threshold Accepting resuelve más instancias del problema que
Búsqueda local con una penalidad en cantidad de operaciones.

Encontramos que no hay relación entre la dificultad de resolver los problemas de
manera lógico deductivo con la resolución algorítmica utilizando estos métodos.

La facilidad de implementación de estos algoritmos los hacen excelentes
candidatos para poder determinar una solución inicial para un problema
combinatorio de estas características. Sin embargo es probable que no encuentren
el mínimo global dado las limitaciones que presentan en su diseño.

\clearpage

\bibliography{citas}

\end{document}
